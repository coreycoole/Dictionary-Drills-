{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the MLP above, which runs reasonably quickly. Copy that code down here and see if you can tune it to achieve 99% accuracy with a Multi-Layer Perceptron. Does it run faster than the recurrent or convolutional neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Import the backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Change shape \n",
    "# Note that our images are 28*28 pixels, so in reshaping to arrays we want\n",
    "# 60,000 arrays of length 784, one for each image\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# Convert to float32 for type consistency\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize values to 1 from 0 to 255 (256 values of pixels)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Print sample sizes\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "# So instead of one column with 10 values, create 10 binary columns\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/coreycoole/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/coreycoole/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Start with a simple sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add dense layers to create a fully connected MLP\n",
    "# Note that we specify an input shape for the first layer, but only the first layer.\n",
    "# Relu is the activation function used\n",
    "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "# Dropout layers remove features and fight overfitting\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# End with a number of units equal to the number of classes we have for our outcome\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/coreycoole/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.4411 - acc: 0.8709 - val_loss: 0.1893 - val_acc: 0.9414\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2028 - acc: 0.9390 - val_loss: 0.1382 - val_acc: 0.9601\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1586 - acc: 0.9522 - val_loss: 0.1147 - val_acc: 0.9661\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1331 - acc: 0.9596 - val_loss: 0.1159 - val_acc: 0.9639\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1171 - acc: 0.9646 - val_loss: 0.0993 - val_acc: 0.9713\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1053 - acc: 0.9675 - val_loss: 0.1000 - val_acc: 0.9698\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0984 - acc: 0.9707 - val_loss: 0.0950 - val_acc: 0.9729\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0895 - acc: 0.9730 - val_loss: 0.0869 - val_acc: 0.9751\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0850 - acc: 0.9737 - val_loss: 0.0896 - val_acc: 0.9733\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0889 - val_acc: 0.9743\n",
      "Test loss: 0.08892666504264343\n",
      "Test accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning MLP Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2440 - acc: 0.9254 - val_loss: 0.0983 - val_acc: 0.9690\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1024 - acc: 0.9688 - val_loss: 0.0766 - val_acc: 0.9777\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0728 - acc: 0.9778 - val_loss: 0.0779 - val_acc: 0.9770\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0613 - acc: 0.9822 - val_loss: 0.0760 - val_acc: 0.9798\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.0863 - val_acc: 0.9786\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0442 - acc: 0.9869 - val_loss: 0.0886 - val_acc: 0.9784\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0378 - acc: 0.9883 - val_loss: 0.0736 - val_acc: 0.9828\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0337 - acc: 0.9905 - val_loss: 0.0966 - val_acc: 0.9787\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0316 - acc: 0.9906 - val_loss: 0.0863 - val_acc: 0.9809\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0290 - acc: 0.9919 - val_loss: 0.0922 - val_acc: 0.9828\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0259 - acc: 0.9923 - val_loss: 0.0991 - val_acc: 0.9797\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0244 - acc: 0.9931 - val_loss: 0.1049 - val_acc: 0.9816\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0238 - acc: 0.9931 - val_loss: 0.1008 - val_acc: 0.9831\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0224 - acc: 0.9942 - val_loss: 0.1073 - val_acc: 0.9833\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0214 - acc: 0.9940 - val_loss: 0.0960 - val_acc: 0.9833\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0198 - acc: 0.9945 - val_loss: 0.1123 - val_acc: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0207 - acc: 0.9947 - val_loss: 0.1045 - val_acc: 0.9838\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0205 - acc: 0.9946 - val_loss: 0.1056 - val_acc: 0.9835\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0182 - acc: 0.9952 - val_loss: 0.1131 - val_acc: 0.9840\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0173 - acc: 0.9957 - val_loss: 0.1073 - val_acc: 0.9833\n",
      "Test loss: 0.10731052318065216\n",
      "Test accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2424 - acc: 0.9241 - val_loss: 0.1062 - val_acc: 0.9668\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1008 - acc: 0.9695 - val_loss: 0.0857 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0740 - acc: 0.9780 - val_loss: 0.0759 - val_acc: 0.9778\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0601 - acc: 0.9818 - val_loss: 0.0736 - val_acc: 0.9783\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0507 - acc: 0.9849 - val_loss: 0.0737 - val_acc: 0.9818\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0430 - acc: 0.9876 - val_loss: 0.0685 - val_acc: 0.9823\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0382 - acc: 0.9885 - val_loss: 0.0990 - val_acc: 0.9772\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0340 - acc: 0.9901 - val_loss: 0.0769 - val_acc: 0.9818\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0309 - acc: 0.9903 - val_loss: 0.0895 - val_acc: 0.9820\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0299 - acc: 0.9917 - val_loss: 0.0990 - val_acc: 0.9798\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0269 - acc: 0.9922 - val_loss: 0.0991 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.1001 - val_acc: 0.9816\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0237 - acc: 0.9934 - val_loss: 0.1040 - val_acc: 0.9805\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.1041 - val_acc: 0.9835\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0199 - acc: 0.9945 - val_loss: 0.1023 - val_acc: 0.9833\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0208 - acc: 0.9945 - val_loss: 0.1118 - val_acc: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.0984 - val_acc: 0.9835\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0180 - acc: 0.9948 - val_loss: 0.1019 - val_acc: 0.9837\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.1035 - val_acc: 0.9840\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0164 - acc: 0.9957 - val_loss: 0.1185 - val_acc: 0.9841\n",
      "Test loss: 0.11846841683642119\n",
      "Test accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed Compiler Loss-Function to \"Binary Crossentropy\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0426 - acc: 0.9853 - val_loss: 0.0189 - val_acc: 0.9933\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0151 - val_acc: 0.9948\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0132 - val_acc: 0.9956\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0130 - val_acc: 0.9958\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0147 - val_acc: 0.9958\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0129 - val_acc: 0.9966\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0136 - val_acc: 0.9965\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0140 - val_acc: 0.9965\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0125 - val_acc: 0.9968\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0129 - val_acc: 0.9970\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0157 - val_acc: 0.9964\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0145 - val_acc: 0.9968\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0155 - val_acc: 0.9970\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0152 - val_acc: 0.9971\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0168 - val_acc: 0.9971\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0174 - val_acc: 0.9966\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0165 - val_acc: 0.9965\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0171 - val_acc: 0.9971\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9968\n",
      "Test loss: 0.018117272389177607\n",
      "Test accuracy: 0.9967799940109253\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greater than 99.67% accuracy at 20 epochs on a Sequential MLP with three dense layers, 512 nodes each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
