{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each, Identify which supervised learning method would best address that particular problem.\n",
    "Explain your reasoning.\n",
    "\n",
    "1 - Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "- target : running times\n",
    "- Using regression, since the trend of running times may be different as the years progress and we may be looking for a result that is not encapsulated within our dataset.\n",
    "- Running times have an underlying classification ‘Events’\n",
    "- Choose a Random Forest Regressor or a Support Vector Machine Regressor with appropriate Kernel to find the optimal boundary.\n",
    "\n",
    "2 - You have more features (columns) than rows (observations) in your dataset.\n",
    "- target; dimensionality reduction\n",
    "- Lasso Regression: L1 regularization,prevent s overfitting, works as an embedded feature selection tool. forces small parameters to equal zero.\n",
    "- Principal Component Analysis: Works for normally distributed data, though it assumes the relationship between variables is linear.\n",
    "- Works best when the variables involved range from weak to moderately strong correlations.\n",
    "- Partial Least Squares Regression: flexibility allows it to be used in situations where the use of traditional multivariate methods is severely limited, such as when there are fewer observations than predictor variables.\n",
    "\n",
    "3 - Identify the most important characteristic predicting the likelihood of being jailed before age 20.\n",
    "- target: most important feature  \n",
    "- Random Forest Classifier:\n",
    "- Can handle various types of data, feature selection is part of the model\n",
    "- With gradient boosting; less prone to overfitting, minimize the negative log-likelihood\n",
    "\n",
    "\n",
    "4 - Implement a filter to ‘highlight’ emails that might be important to the recipient.\n",
    "- target: binary variable; spam vs ham classifier\n",
    "- Naive Bayes: Simple implementation, practical, very fast processing time, Relies on probabilities, actually train the classifier with more data than could fit into memory at one time.\n",
    "- Random Forest Classifier: Features based on address, title content, ect.\n",
    "\n",
    "5 - You have 1000+ features.\n",
    "- target: dimensionality reduction\n",
    "- If continuous target class:\n",
    "- Lasso Regression, P.C.A., Partial Least Squares Regression\n",
    "- If categorical target class:\n",
    "- One-hot encoding with Principal Component Analysis, or Multiple Correspondence Analysis\n",
    "\n",
    "6 - Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "- target: binary class, to buy, not buy\n",
    "- Random Forest Classifier, or Logistic Regression for explanatory purposes based on the model coefficients. \n",
    "\n",
    "7 - Your dataset dimensions are 982400 x 500.\n",
    "- target: processing speed optimization\n",
    "- Ridge Regression: minimizes variance, prevents overfitting\n",
    "- Lasso Regression: feature selection, optimize processor time\n",
    "- PCA/MCA: depending on data type, reduce dimensionality\n",
    "\n",
    "8 - Identify faces in an image.\n",
    "- Geometric/Template Based:\n",
    "- SVM, PCA, Linear Discriminant Analysis, Kernel methods, Trace Transforms, Discrete Cosine Transforms.\n",
    "- P.C.A.: dimensionality reduction\n",
    "- D.C.T.: based on Fourier discrete transform, compacting the varationsit can be used to transform images allowing for an efficient dimensionality reduction.\n",
    "- L.D.A.: find the linear combination of features while preserving class separability, model the difference between levels. For each level the LDA obtains differences in multiple projection vectors.\n",
    "  \n",
    "9 - Predict which of 3 ice cream flavors will be most popular with boys versus girls.\n",
    "- Target: ice cream popularity in 2 groups, boys and girls\n",
    "- KNN: easily implemented, simple processing, distance-weighted\n",
    "- Support Vector Classifier with three dimensional kernel transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
